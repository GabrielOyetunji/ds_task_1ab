{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1: E-commerce Data Exploration\n",
    "\n",
    "**Objective**: Explore and understand the raw e-commerce dataset to inform cleaning strategies.\n",
    "\n",
    "**Dataset**: Online Retail dataset with transaction records including:\n",
    "- InvoiceNo: Transaction identifier\n",
    "- StockCode: Product identifier\n",
    "- Description: Product description\n",
    "- Quantity: Number of items purchased\n",
    "- UnitPrice: Price per item\n",
    "- CustomerID: Customer identifier\n",
    "- Country: Customer location\n",
    "\n",
    "**Expected Outcome**: Identify data quality issues and design appropriate cleaning strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Data Loading\n",
    "\n",
    "Load the raw dataset and examine its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load with correct encoding\n",
    "df = pd.read_csv(\"data/raw/dataset.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment\n",
    "\n",
    "Check for missing values, data types, and potential issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Basic info\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "missing = df.isna().sum()\n",
    "print(missing[missing > 0])\n",
    "\n",
    "# Missing percentages\n",
    "print(\"\\nMissing Percentages:\")\n",
    "missing_pct = (df.isna().sum() / len(df) * 100).round(2)\n",
    "print(missing_pct[missing_pct > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Observations:\n",
    "- **CustomerID**: High percentage of missing values (~25%)\n",
    "- **Description**: Some missing product descriptions\n",
    "- These missing values will need to be handled during cleaning\n",
    "\n",
    "**Decision**: Will remove rows with missing critical fields (Description, StockCode) but keep CustomerID optional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Corruption Analysis\n",
    "\n",
    "Check for special characters and corrupted data in text fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Sample StockCode values\n",
    "print(\"Sample StockCode values (including potential corruption):\")\n",
    "print(df['StockCode'].value_counts().head(20))\n",
    "\n",
    "# Check for special characters\n",
    "special_chars = df['StockCode'].astype(str).str.contains(r'[^A-Za-z0-9]', regex=True)\n",
    "print(f\"\\nStockCodes with special characters: {special_chars.sum():,}\")\n",
    "\n",
    "# Sample corrupted values\n",
    "print(\"\\nExamples of corrupted StockCodes:\")\n",
    "print(df[special_chars]['StockCode'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Findings:\n",
    "- StockCode contains special characters that need cleaning\n",
    "- Some codes have symbols like Ã, ö, ^ that indicate encoding issues\n",
    "\n",
    "**Solution**: Apply regex cleaning to remove all non-alphanumeric characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Cleaning Functions\n",
    "\n",
    "Test regex patterns for data cleaning before implementing in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import re\n",
    "\n",
    "def clean_stockcode(x):\n",
    "    \"\"\"Remove non-alphanumeric characters from StockCode\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    return re.sub(r'[^A-Za-z0-9]', '', str(x))\n",
    "\n",
    "# Test on sample\n",
    "test_codes = df['StockCode'].head(100)\n",
    "cleaned_codes = test_codes.apply(clean_stockcode)\n",
    "\n",
    "print(\"Before and After Cleaning:\")\n",
    "comparison = pd.DataFrame({\n",
    "    'Original': test_codes,\n",
    "    'Cleaned': cleaned_codes\n",
    "})\n",
    "print(comparison[comparison['Original'] != comparison['Cleaned']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Numeric Field Analysis\n",
    "\n",
    "Examine Quantity and UnitPrice for invalid values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Quantity analysis\n",
    "print(\"Quantity Statistics:\")\n",
    "print(df['Quantity'].describe())\n",
    "\n",
    "# Check for negative quantities\n",
    "negative_qty = df['Quantity'] < 0\n",
    "print(f\"\\nNegative quantities: {negative_qty.sum():,} ({negative_qty.sum()/len(df)*100:.2f}%)\")\n",
    "\n",
    "# Price analysis\n",
    "print(\"\\nUnitPrice Statistics:\")\n",
    "print(df['UnitPrice'].describe())\n",
    "\n",
    "# Check for zero/negative prices\n",
    "invalid_price = df['UnitPrice'] <= 0\n",
    "print(f\"\\nInvalid prices (≤0): {invalid_price.sum():,} ({invalid_price.sum()/len(df)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights:\n",
    "- Negative quantities likely represent returns/cancellations\n",
    "- Zero prices are data quality issues\n",
    "\n",
    "**Decision**: Filter to keep only Quantity > 0 and UnitPrice > 0 for valid transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Unique Products Analysis\n",
    "\n",
    "Understand the distribution of unique products for vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Count unique products\n",
    "unique_products = df['StockCode'].nunique()\n",
    "print(f\"Unique StockCodes: {unique_products:,}\")\n",
    "\n",
    "# Check descriptions per StockCode\n",
    "desc_per_code = df.groupby('StockCode')['Description'].nunique()\n",
    "print(f\"\\nStockCodes with multiple descriptions: {(desc_per_code > 1).sum():,}\")\n",
    "\n",
    "# Top products by transaction count\n",
    "print(\"\\nTop 10 Products by Transaction Count:\")\n",
    "top_products = df['StockCode'].value_counts().head(10)\n",
    "print(top_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Next Steps\n",
    "\n",
    "### Data Quality Issues Identified:\n",
    "1. Special characters in StockCode (encoding corruption)\n",
    "2. Missing values in CustomerID (~25%) and Description\n",
    "3. Negative quantities (returns)\n",
    "4. Zero/negative prices\n",
    "5. Some StockCodes have multiple descriptions\n",
    "\n",
    "### Cleaning Strategy:\n",
    "1. ✅ Remove special characters from all text fields\n",
    "2. ✅ Filter Quantity > 0 and UnitPrice > 0\n",
    "3. ✅ Remove rows with empty critical fields\n",
    "4. ✅ Group by StockCode and take first description\n",
    "5. ✅ Remove duplicates\n",
    "\n",
    "### Expected Outcome:\n",
    "- Reduction from 541,910 to ~400,000 rows (26% removal)\n",
    "- Clean dataset ready for embedding generation\n",
    "- ~3,600 unique products for vector database\n",
    "\n",
    "**Next**: Implement cleaning in `data_cleaner.py` service"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
